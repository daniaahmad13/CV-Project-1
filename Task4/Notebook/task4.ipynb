{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = \"C:/Users/Dell/DataScience/Lums/CS5310/MiniProject/Task4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Yolo\n",
    "yolo_net = cv2.dnn.readNet( load_dir + \"/weights3hrs/mask-yolov3_10000.weights\", load_dir + \"/weights3hrs/mask-yolov3.cfg\")\n",
    "layer_names = yolo_net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in yolo_net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Person\", \"mask\", \"noMask\"]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "colors = [0, 122, 255] # color of boxes\n",
    "# print(colors)\n",
    "# print(len(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = {\n",
    "    \"Camera-1\": load_dir + \"/Videos/campus4-c0.mp4\",\n",
    "    \"Camera-2\": load_dir + \"/Videos/campus4-c1.mp4\",\n",
    "    \"Camera-3\": load_dir + \"/Videos/campus4-c2.mp4\"    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Homography_matrix = {}\n",
    "    \n",
    "Homography_matrix[\"Camera-1\"] = np.array([[-0.211332, -0.405226, 70.781223], [-0.019746, -1.564936, 226.377280], [-0.000025, -0.001961, 0.160791]])\n",
    "Homography_matrix[\"Camera-2\"] = np.array([[0.000745, 0.350335, -98.376103], [-0.164871, -0.390422, 54.081423], [0.000021, -0.001668, 0.111075]])\n",
    "Homography_matrix[\"Camera-3\"] = np.array([[0.089976, 1.066795, -152.055667], [-0.116343, 0.861342, -75.122116], [0.000015, 0.001442, -0.064065]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Available_Cams(cams_detail,  starting = 0):\n",
    "    available_cams = {}\n",
    "\n",
    "    for key, video_address in cams_detail.items():\n",
    "        cam = cv2.VideoCapture(video_address)\n",
    "        if cam.isOpened() == True:\n",
    "            cam.set(1,starting)\n",
    "            available_cams[key] = cam\n",
    "            \n",
    "    return available_cams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_Homograpy_On_Frames(current_frame):\n",
    "    merge_image = []\n",
    "    flag = True    \n",
    "    for key in list(current_frame.keys()):\n",
    "        new_image = cv2.warpPerspective(current_frame[key], Homography_matrix[key] ,(600,600)).astype('uint32')        \n",
    "        if flag == True:\n",
    "            merge_image = new_image\n",
    "            flag = False\n",
    "        else:\n",
    "            merge_image += new_image\n",
    "        \n",
    "    length = len(current_frame.keys())\n",
    "    merge_image =  np.array((np.array(merge_image) / length)).astype('uint8')\n",
    "    return merge_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Object_Detection(current_frame):\n",
    "    \n",
    "    object_detections = {}\n",
    "    \n",
    "    for key in list(current_frame.keys()):\n",
    "        \n",
    "        begin = time.time()\n",
    "        # Image\n",
    "        img = current_frame[key]\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "        # Detecting objects\n",
    "        blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "        yolo_net.setInput(blob)\n",
    "        outs = yolo_net.forward(output_layers)\n",
    "\n",
    "        # Showing informations on the screen\n",
    "        detection_data = {\"Boxes\":[], \"ClassIDs\": [], \"Confidences\": [], \"Center\": [] }\n",
    "        \n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.4:\n",
    "                    # Object detected\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    # Rectangle coordinates\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    detection_data[\"Boxes\"].append([x, y, w, h])\n",
    "                    detection_data[\"ClassIDs\"].append(class_id)\n",
    "                    detection_data[\"Confidences\"].append(float(confidence))\n",
    "#                     detection_data[\"Center\"].append([[center_x], [center_y ], [1]])\n",
    "                    detection_data[\"Center\"].append([center_x, center_y+ int(h/2)])\n",
    "#                     detection_data[\"Center\"].append([center_x, center_y])\n",
    "    \n",
    "        \n",
    "        object_detections[key] = detection_data\n",
    "    \n",
    "    show_bounding_boxes(current_frame, object_detections)\n",
    "    return object_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bounding_boxes(current_frame, object_detections):\n",
    "\n",
    "    for key in current_frame.keys():\n",
    "        img = current_frame[key]\n",
    "        detection_data = object_detections[key]\n",
    "        \n",
    "        indexes = cv2.dnn.NMSBoxes(detection_data[\"Boxes\"], detection_data[\"Confidences\"], 0.5, 0.4)\n",
    "        font = cv2.ACCESS_MASK\n",
    "        \n",
    "        for i in range(len(detection_data[\"Boxes\"])):\n",
    "            if i in indexes:\n",
    "                x, y, w, h = detection_data[\"Boxes\"][i]\n",
    "                label = str(classes[detection_data[\"ClassIDs\"][i]]) + str(np.around(detection_data[\"Confidences\"][i],2)*100) + \"%\"\n",
    "                color = colors[detection_data[\"ClassIDs\"][i]]\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
    "                cv2.putText(img, label , (x, y-5), font, 0.4, color, 1)\n",
    "\n",
    "        cv2.imshow(key, img)\n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_point_top_view(new_locations):\n",
    "    path_top_image = load_dir + \"/Images/top_view.jpg\"\n",
    "    new_image = cv2.imread(path_top_image, 1)\n",
    "    for points in new_locations:\n",
    "        new_image = cv2.circle(new_image, (points[0], points[1]), 5, (255, 0, 0), 5)\n",
    "        \n",
    "    cv2.imshow(\"Top View \", new_image)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_on_top_view(object_detections, top_view_frame):\n",
    "    \n",
    "    new_image = top_view_frame\n",
    "    new_locations = []\n",
    "    booleanV = True\n",
    "    for key in object_detections:\n",
    "        detection_data = object_detections[key]\n",
    "        indexes = cv2.dnn.NMSBoxes(detection_data[\"Boxes\"], detection_data[\"Confidences\"], 0.5, 0.4)\n",
    "        \n",
    "        for i in range(len(detection_data[\"Boxes\"])):\n",
    "            if i in indexes:\n",
    "                center = detection_data[\"Center\"][i]                \n",
    "                new_location =  np.dot(Homography_matrix[key], np.array([[center[0]], [center[1]], [1]]) )\n",
    "                new_location = new_location / new_location[2]\n",
    "                new_image = cv2.circle(new_image, (int(new_location[0]), int(new_location[1])), 5, (255, 0, 0), 5)\n",
    "                if booleanV == True:\n",
    "                    new_locations.append( [int(new_location[0]), int(new_location[1])] )\n",
    "        booleanV = False\n",
    "        \n",
    "    show_point_top_view(new_locations)\n",
    "    \n",
    "    cv2.imshow(\"Merged\", new_image)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Image(available_cams):\n",
    "    \n",
    "    cam_keys = list(available_cams.keys())\n",
    "\n",
    "    save_path =  load_dir + '/FinalVideo/top_view_video2.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    top_view_video = cv2.VideoWriter(save_path, fourcc, 25, (600,600))    \n",
    "\n",
    "    while len(cam_keys) == len(available_cams):\n",
    "        current_frame = {}        \n",
    "        for i , key in enumerate(cam_keys):\n",
    "            is_open , frame = available_cams[key].read()\n",
    "            if is_open == True:\n",
    "                current_frame[key] = frame\n",
    "            else:\n",
    "                cam_keys.pop(i)\n",
    "                \n",
    "        if len(cam_keys) == len(available_cams):\n",
    "            object_detections = Object_Detection(current_frame)\n",
    "            top_view_frame = Apply_Homograpy_On_Frames(current_frame)\n",
    "            label_on_top_view(object_detections, top_view_frame)\n",
    "            top_view_video.write(top_view_frame)\n",
    "    \n",
    "    for key in available_cams.keys():\n",
    "        available_cams[key].release()\n",
    "        \n",
    "    top_view_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should run for 6-7 mins so that complete video is stored. If not then the video stored will be incomplete and will\n",
    "# not open.\n",
    "available_cams = Get_Available_Cams(cameras, 390)\n",
    "read_Image(available_cams)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
